{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82870ba0-6291-4f4a-97c5-bb0035c43511",
   "metadata": {},
   "source": [
    "Ans.1     \n",
    "Model said to be underfitting model that neither perform perfectly on training data nor perform on testing data. This model can not capture underline trend of data. This model predicts more number of incorrect assumptions.\n",
    "To reduce underfitting, we need to increase model complexity, to increase the number of features, increase the duration of training.\n",
    "\n",
    "Model said to be overfitting model that perform perfectly on training data, does not predict perfectly on tresting data. Model is too complicated, it makes ineffective. We need to decrese complex. We need to seelect features that used to predict assumption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa82af60-b73d-4310-9a8d-80bbec09f2e8",
   "metadata": {},
   "source": [
    "Ans.2 -     \n",
    "Overlifting can be reduced by following steps -   \n",
    "i.  provide more accurate data instead of noise data   \n",
    "ii. Train model with more data   \n",
    "iii. Make model less complex"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba4dba2d-2d93-445e-9e61-f646df8a40a7",
   "metadata": {},
   "source": [
    "Ans.3 :-             \n",
    "Underfitting model neither perform correctly on taining data nor under testing data.  Model does not learn too much \n",
    "on training data. It predicts more number of incorrect  data. Senarios where unfitting can occur :-     \n",
    "i. Uncleaned data   \n",
    "ii. High bias in the model    \n",
    "iii. Less training data    \n",
    "iv. Model is too simple    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc95d8d8-ead8-48fb-a818-0d1eb647b6cb",
   "metadata": {},
   "source": [
    "Ans.4:-     \n",
    "we have to find out balance between bias and variance in our model. We should be ensure our model captures all \n",
    "esential points without capturing noise between data. This is called Bias-Variance tradeoff. Bias and variance inversely propotional to each other. At low bias and low variance, model perfectly predicts all values. Low bias and high variance predicts just aroung the points. High bias and low variance predicts all points at same but away from \n",
    "our expected value. In case of high bias and high variance, model performs very low."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd319521-0c8a-4766-b79a-98e99f55d401",
   "metadata": {},
   "source": [
    "Ans.5 -   \n",
    "We can detect overfitting or underfitting of the model by prediction error on the training and  testing data.\n",
    "Model is overfitting when it performs significantly well on training data, but performs bad on testing data.\n",
    "In the case of underfitting, model neuther perform good on training and testing data.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29b4bb83-95a8-43ad-9c6f-80bb0d3a57ba",
   "metadata": {},
   "source": [
    "Ans 6 -     \n",
    "Bias - when algorithm is applied in a model but it does not fit well, it creats bias in between assumption and prediction. This\n",
    "case neither model perform on training data nor in test data. High level of bias leads to underfit.\n",
    "\n",
    "Variance - Variance indicates how much estimate of the target function varies when different training data were used. High variance leads to overfitting. It occurs if most noise on training data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43217af0-3c79-4e5a-9522-58d301bf8e58",
   "metadata": {},
   "source": [
    "Ans 7 -      \n",
    "Regularization is a technique used to redue reudce errors by fitting function in training data which will avoid overfitting of the model. It normalizes and moderates weights attached to a feature so that algorithms do not rely on just a few features to predict the result.\n",
    "\n",
    "Three types of regularization techniques :-     \n",
    "i.   Ridge Regression (L2 Norm)     \n",
    "ii.  Lasso (L1 Norm)     \n",
    "iii. Dropout      \n",
    " \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e1ce5ea-e20a-4d33-a5ae-bdb5c2be5e8b",
   "metadata": {},
   "source": [
    "Ridege Regression technique we add sum of square of weight fuction to regular loss function, we get new loss function which manages error. In Lasso technique we add sum of absolute weight function to regular loss function to normalize the loss. Dropout techinue used in neural networks, it prevents complex coadoption."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
